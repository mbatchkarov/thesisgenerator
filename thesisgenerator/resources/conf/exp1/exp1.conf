name=tests-exp1
debug=True

training_data=thesisgenerator/resources/test-tr
test_data=thesisgenerator/resources/test-ev
output_dir=thesisgenerator/resources/conf/exp1/output

joblib_caching=False

min_test_features = 0
min_train_features = 0

[feature_extraction]
    run=True
    vectorizer=thesisgenerator.plugins.bov.ThesaurusVectorizer
    analyzer=ngram
    
    decode_token_handler=thesisgenerator.plugins.bov_feature_handlers.SignifiedOnlyFeatureHandler

    #extra options required by the Bag-of-Vectors project Vectorizer
    sim_threshold=0
    k=3
    lemmatize=True
    use_pos=True
    coarse_pos=True
    replace_all=False
    use_tfidf=False
    record_stats=True
    use_signifier_only=True
    include_self=False
    
    [[train_time_opts]]
        extract_unigram_features=J,N,V
        extract_phrase_features=,
    [[decode_time_opts]]
        extract_unigram_features=J,N,V
        extract_phrase_features=,

[tokenizer]
	lowercase= True

[crossvalidation]
    #if false, a single run with an 80/20 split is performed
    run=True
    # permitted values are 'kfold', 'skfold', 'loo', 'bootstrap' or 'oracle'. k-fold requires only the 'k' option (number of folds)
    # to be set. 'skfold' performs stratified k-fold. 'bootstrap' required both 'k' (number of bootstraps) and 'ratio'
    # (the proportion of the dataset to include in the train split, 0<ratio<1, the rest of the data is used for testing).
    # If 'oracle' the training data is used for testing too. subsampled_test_set requires k and sample_size
    type=subsampled_test_set
    k=2
    ratio=0.8
    sample_size=3

	stream_data=true
	# seen_data_evaluator needs to be a callable that takes a list of x and y values
	validation_slices=#utils.gorkana_200_seen_positives_validation

[split_data]
    run=true
    stream_data=true

[feature_selection]
    run=False
    # the selection method should be one of the classes defined in
    # sklearn.feature_selection - any parameters the class initialiser takes
    # can be defined below and they will be dynamically assigned to the init call
    method=thesisgenerator.composers.feature_selectors.VectorBackedSelectKBest	
    scoring_function=sklearn.feature_selection.chi2
    k=999999

[dimensionality_reduction]
    run=False
    #alternatives: sklearn.decomposition.PCA/ ProjectedGradientNMF
    # PCA produces negative feature values (counts) which makes NaiveBayes rather upset
    method=sklearn.decomposition.ProjectedGradientNMF
    #must be less than each of the dimensions of the feature vector matrix
    n_components=5
    whiten=True #only applicable to PCA

[vector_sources]
	neighbours_file = thesisgenerator/resources/exp0-0a.strings
 	sim_threshold = 0
	include_self = False
	
	[[thesisgenerator.composers.vectorstore.UnigramDummyComposer]]
		run=True
	[[thesisgenerator.composers.vectorstore.AdditiveComposer]]
		run=False
	[[thesisgenerator.composers.vectorstore.MultiplicativeComposer]]
		run=False
	[[thesisgenerator.composers.vectorstore.BaroniComposer]]
		run=False
		file_path = /mnt/lustre/scratch/inf/mmb28/FeatureExtractionToolkit/exp6-12c/
		
[classifiers]
    [[sklearn.naive_bayes.MultinomialNB]]
		run=True
	[[sklearn.naive_bayes.BernoulliNB]]
		run=True

[evaluation]

	# the default setting for the sklearn's metrics is to work per-class
    [[sklearn.metrics.precision_score]]
        run=True

	[[sklearn.metrics.recall_score]]
		run=True

	[[sklearn.metrics.f1_score]]
		run=True
