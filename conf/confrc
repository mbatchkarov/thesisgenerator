name=string() # used to identify output files
debug=boolean(default=False) #if true, pipelines will be pickled and feature vectors will be dumped as csv
joblib_caching=boolean(default=False) # for tokenizer, the whole  corpus can be loaded from disk
shuffle_targets=boolean(default=False) # randomly change the labels of all documents, sanity check

training_data=string(default='')
test_data=string(default='')

[feature_extraction]
    run=boolean(default=True)
    vectorizer=string # class of vectorizer
    input_generator=string(default="")

	# The below options have defaults in the scikit Vectorizer init
    input=option('content', 'filename', 'file')
    charset=string
    decode_error=string
    strip_accents=string
    lowercase=boolean(default=False)
    token_pattern=string
#     ngram_range=tuple() #ngram_range had to be in the format "1,3"
    min_df=integer
    max_df=integer
    analyser=string
    preprocessor=string
    tokenizer=string
    max_features=integer(default=None)
    vocabulary=string
    binary=boolean
    use_tfidf=boolean
    
    extract_AN_features=boolean(default=True) # whether to extract adjective-noun compounds when dependency trees are available
    extract_NN_features=boolean(default=True)
    extract_VO_features=boolean(default=True)
    extract_SVO_features=boolean(default=True)
    unigram_feature_pos_tags=list # for each extracted unigram feature, check that its PoS is contained here
    remove_features_with_NER=boolean(default=False) # whether to remove document features that contain a token with NER tag  ORG, PERS, LOC- these aren't composable

    # extra options required by the Bag-of-Vectors project Vectorizer
    #train_thesaurus_files=list(default=list()) # a list of files to be read to a dict-like object and passed to the vectorizer at train time
    #decode_thesaurus=string(default='') # a callable to be used instead of the real thesaurus at decode time; used to build a "random or constant" thesaurus as a sanity-check

    random_neighbour_thesaurus=boolean(default=False) # if true, k random in-vocabulary neighbours will be returned at decode time
    k=integer(min=0) # how many neighbours per entry to read
    lemmatize=boolean(default=True) 
    use_pos=boolean(default=True) # big cat -> big/JJ cat/NNS
	coarse_pos=boolean(default=True) 
	normalise_entities=boolean(default=False) # all named entities -> PERSON/LOCATION/MISC

	record_stats=boolean(default=False)
	sim_compressor=string(default='thesisgenerator.utils.misc.noop') # how to scale the sim between two features in a thesaurus when replacing

	train_token_handler=string(default='thesisgenerator.plugins.bov_feature_handlers.BaseFeatureHandler') # specified which class to handle the convertion of tokens/ngrams to features, signifier/signified
	decode_token_handler=string(default='thesisgenerator.plugins.bov_feature_handlers.BaseFeatureHandler')


[tokenizer]
	lowercase=boolean
    keep_only_IT=boolean(default=False)
    remove_stopwords=boolean(default=False)
	remove_short_words=boolean(default=False)

[vector_sources] # this section will eventually replace all thesaurus-related options. There will not be a pre-computed sim matrix, just vectors in a suitable datastructure that allows fast online sim calculation
	unigram_paths = list(default=list()) # path to either a Byblo events files or neighbours.strings file. If events, you must specify that precomputed=False
	precomputed=boolean(default=True) # whether the unigram_paths contain vectors or precomputed term similarities
	include_self=boolean(default=False) # whether the thesaurus loader includes an entry as its own nearest neighbour
	sim_threshold=float(default=0.0) # exclude neighbours from thesaurus if sim is less than threshold
	reduce_dimensionality=boolean(default=False) # whether the dimensionality of the lexical unigram vectors should be reduced. This greatly speeds up later operations on these vectors.
	dimensions = integer(default=1000) # if reduce_dimensionality, how many dimensions should the resultant vectors have
	allow_lexical_overlap = boolean(default=True) # when a thesaurus is loaded from disk and this is set to true, neighbours that overlap lexically with the base entry will be removed. See unit test for spec.
	
	[[thesisgenerator.composers.vectorstore.AdditiveComposer]]
		run=boolean(default=False)
	[[thesisgenerator.composers.vectorstore.MultiplicativeComposer]]
		run=boolean(default=False)
	[[thesisgenerator.composers.vectorstore.BaroniComposer]]
		run=boolean(default=False)
		file_path=list(default=list())
		
[crossvalidation]
	run=boolean()
	type = option('kfold', 'skfold', 'loo', 'bootstrap', 'oracle', default = 'kfold')
	k=integer(min=1,max=100)
	ratio=float()
    sample_size=integer()
    random_state=integer(default=0)

[split_data]
    run=boolean()
    stream_data=boolean()

[feature_selection]
    run=boolean()
    method=string(default='thesisgenerator.composers.feature_selectors.VectorBackedSelectKBest')
    scoring_function=string
    ensure_vectors_exist=boolean(default=False)
    k=integer(default=99999999999999)
    alpha=float
    percentile=int

[dimensionality_reduction]
    run=boolean(default=False)
    method=string(default=sklearn.decomposition.ProjectedGradientNMF)
    n_components=integer(min=0)
    whiten=boolean

[classifiers]
    [[sklearn.naive_bayes.MultinomialNB]]
    	run=boolean(default=False)
		alpha=float()

	[[sklearn.naive_bayes.BernoulliNB]]
    	run=boolean(default=False)
		alpha=float()

    [[sklearn.neighbors.KNeighborsClassifier]]
    	run=boolean(default=False)
    	k=integer()

    [[sklearn.linear_model.LogisticRegression]]
		run=boolean(default=False)

    [[sklearn.svm.SVC]]
    	run=boolean(default=False)
    	kernel=option('linear','rbf', 'poly')
		C=float(default=50.)
    	gamma=float(default=0.01)


    [[sklearn.svm.LinearSVC]]
    	run=boolean(default=False)

	[[thesisgenerator.classifiers.MostCommonLabelClassifier]]
	    run=boolean(default=False)
	    
    [[thesisgenerator.classifiers.MultinomialNBWithBinaryFeatures]]
	    run=boolean(default=False)
		alpha=float()
		threshold=float(default=0.0)

[evaluation]
    [[sklearn.metrics.precision_score]]
        run=boolean(default=False)
		average=option('micro', 'macro', 'weighted', default=None)

	[[sklearn.metrics.recall_score]]
		run=boolean(default=False)
		average=option('micro', 'macro', 'weighted', default=None)

	[[sklearn.metrics.f1_score]]
		run=boolean(default=False)
        average=option('micro', 'macro', 'weighted', default=None)

	[[thesisgenerator.metrics.macroavg_prec]]
    	run=boolean(default=False)

	[[thesisgenerator.metrics.macroavg_rec]]
    	run=boolean(default=False)

	[[thesisgenerator.metrics.macroavg_f1]]
    	run=boolean(default=False)

    [[thesisgenerator.metrics.microavg_prec]]
    	run=boolean(default=False)

	[[thesisgenerator.metrics.microavg_rec]]
    	run=boolean(default=False)

	[[thesisgenerator.metrics.microavg_f1]]
    	run=boolean(default=False)

    [[sklearn.metrics.accuracy_score]]
        run=boolean(default=False)


