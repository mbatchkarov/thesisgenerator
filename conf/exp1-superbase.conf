name = ------------------------
debug = False
training_data = ------------------------
output_dir = ------------------------
gzip_resources = True
min_test_features = 1
min_train_features = 0.1

[feature_extraction]
    run = True
    vectorizer = thesisgenerator.plugins.bov.ThesaurusVectorizer
    input = content
    decode_error = replace
    stop_words = english
    min_df = 10
    ngram_range = 1,1
	ngram_range_decode = 0,0 # not interested in unigrams at decode time
    unigram_feature_pos_tags=N,J 
    analyzer = ngram
    sim_threshold = 0.01
    k = 3
    lemmatize = True
    use_pos = True
    coarse_pos = True
    normalise_entities = False
    use_tfidf = False
    replace_all = False
    record_stats = False
    sim_compressor=------------------------
    decode_token_handler = thesisgenerator.plugins.bov_feature_handlers.SignifiedOnlyFeatureHandler
    extract_AN_features=------------------------
    extract_NN_features=------------------------
    extract_VO_features=False
    extract_SVO_features=False
    remove_features_with_NER=True
    random_neighbour_thesaurus=False
[tokenizer]
    lowercase = True
    keep_only_IT = False
    remove_stopwords = True
    remove_short_words = False
	remove_long_words = True # HDF has a max string length and crashes sometimes. >25 chars is probably noise anyway.
[crossvalidation]
    run = True
    type = skfold
    k = 10
    sample_size = ------------------------
    random_state = 0
[feature_selection]
    run = True # needed to run filtering based on log odds score
    must_be_in_thesaurus = True
    min_log_odds_score = 0 # remove features that are associated with both classes
    k = 99999999999 # do not use chi2 

[classifiers]
    [[sklearn.naive_bayes.MultinomialNB]]
        run = True
        alpha = 0.001

    [[sklearn.linear_model.LogisticRegression]]
        run = True
        C = 0.00001
    	
[evaluation]
    [[sklearn.metrics.precision_score]]
        run = True
    [[sklearn.metrics.recall_score]]
        run = True
    [[sklearn.metrics.f1_score]]
        run = True
    [[thesisgenerator.metrics.macroavg_prec]]
        run = True
    [[thesisgenerator.metrics.macroavg_rec]]
        run = True
    [[thesisgenerator.metrics.macroavg_f1]]
        run = True
    [[thesisgenerator.metrics.microavg_prec]]
        run = True
    [[thesisgenerator.metrics.microavg_rec]]
        run = True
    [[thesisgenerator.metrics.microavg_f1]]
        run = True
    [[sklearn.metrics.accuracy_score]]
        run = True
[vector_sources]
    sim_threshold = -9999999999 # we should be loading vectors here, so this is a reasonable threshold.
    neighbours_file = _____________________
    include_self = False
    entry_types_to_load =
    max_neighbours=2000000000
    allow_lexical_overlap = False
    use_shelf = False