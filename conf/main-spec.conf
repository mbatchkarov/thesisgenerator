[feature_extraction]
    run=boolean(default=True)
    vectorizer=string(default="")
    input_generator=string(default="")
    input=option('content', 'filename', 'file',default='content')
    charset=string(default='utf-8')
    charset_error=string(default='strict')
    strip_accents=string(default='ascii')
    lowercase=boolean(default=False)
    token_pattern=string(default='')
#     min_n=integer(default=0)
#     max_n=integer(default=0)
#     min_df=integer(default=0)
#     max_df=integer(default=0)
    analyser=string(default='')
    preprocessor=string(default='')
    tokenizer=string(default='')
    max_features=integer(default=0)
    vocabulary=string(default='')
    binary=boolean(default=False)

    #extra options required by the Bag-of-Vectors project Vectorizer
    thesaurus=string


[crossvalidation]
	run=boolean()
	type = option('kfold', 'skfold', 'loo', 'bootstrap', 'oracle', default = 'kfold')
	k=integer(min=1,max=100,default=5)
	ratio=float()
	
[split_data]
    run=boolean()
    stream_data=boolean()

[feature_selection]
    run=boolean()
    
[classifiers]
    [[sklearn.naive_bayes.MultinomialNB]]

    [[sklearn.neighbors.KNeighborsClassifier]]
    	k=integer()

    [[sklearn.linear_model.LogisticRegression]]

    [[sklearn.svm.SVC]]
    	kernel=option('linear','rbf', 'poly')